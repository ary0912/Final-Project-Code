{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45b98850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique participants in trials: 51\n",
      "Unique participants in repeats: 21\n",
      "Total unique participants across both: 52\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# --- Step 1: Define folder paths ---\n",
    "trials_folder = \"first trials\"   # path to your trials folder\n",
    "repeats_folder = \"repeats\" # path to your repeats folder\n",
    "\n",
    "# --- Step 2: Function to extract participant IDs ---\n",
    "def get_participant_ids(folder):\n",
    "    ids = set()\n",
    "    for fname in os.listdir(folder):\n",
    "        if fname.endswith(\".csv\"):\n",
    "            pid = fname.split(\"_\")[0]   # participant id is before \"_\"\n",
    "            ids.add(pid)\n",
    "    return ids\n",
    "\n",
    "# --- Step 3: Collect IDs from both folders ---\n",
    "trials_ids = get_participant_ids(trials_folder)\n",
    "repeats_ids = get_participant_ids(repeats_folder)\n",
    "\n",
    "all_ids = trials_ids.union(repeats_ids)\n",
    "\n",
    "# --- Step 4: Results ---\n",
    "print(f\"Unique participants in trials: {len(trials_ids)}\")\n",
    "print(f\"Unique participants in repeats: {len(repeats_ids)}\")\n",
    "print(f\"Total unique participants across both: {len(all_ids)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5a657b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Participants in both folders: 20\n",
      "Overlapping IDs: {'071', '057', '054', '056', '047', '032', '006', '049', '042', '062', '036', '058', '041', '009', '029', '016', '011', '065', '021', '048'}\n"
     ]
    }
   ],
   "source": [
    "# Find overlap\n",
    "overlap_ids = trials_ids.intersection(repeats_ids)\n",
    "\n",
    "print(f\"Participants in both folders: {len(overlap_ids)}\")\n",
    "print(\"Overlapping IDs:\", overlap_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d347216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique participants in trials: 51\n",
      "Participant IDs: {'038', '071', '033', '037', '001', '057', '063', '054', '017', '069', '019', '003', '020', '056', '047', '013', '032', '006', '066', '049', '050', '027', '043', '053', '042', '062', '008', '036', '025', '028', '058', '051', '041', '026', '060', '015', '031', '064', '009', '029', '016', '034', '040', '070', '011', '052', '065', '039', '021', '048', '024'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Path to trials folder\n",
    "trials_path = \"first trials\"\n",
    "\n",
    "# Get unique participant IDs from trials folder\n",
    "trials_ids = set([fname.split(\"_\")[0] for fname in os.listdir(trials_path) if fname.endswith(\".csv\")])\n",
    "\n",
    "print(f\"Total unique participants in trials: {len(trials_ids)}\")\n",
    "print(\"Participant IDs:\", trials_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "031f9b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================================================\n",
      "Participant ID Summary (by folder)\n",
      "========================================================================\n",
      "Unique participants in TRIALS: 51\n",
      "  001, 003, 006, 008, 009, 011, 013, 015, 016, 017, 019, 020, 021, 024, 025, 026, 027, 028, 029, 031, ... , 047, 048, 049, 050, 051, 052, 053, 054, 056, 057, 058, 060, 062, 063, 064, 065, 066, 069, 070, 071\n",
      "Unique participants in REPEATS: 21\n",
      "  006, 009, 011, 016, 021, 029, 032, 036, 041, 042, 047, 048, 049, 054, 056, 057, 058, 062, 065, 071, 072\n",
      "\n",
      "========================================================================\n",
      "Combined Participants\n",
      "========================================================================\n",
      "Union (TRIALS ∪ REPEATS): 52\n",
      "  001, 003, 006, 008, 009, 011, 013, 015, 016, 017, 019, 020, 021, 024, 025, 026, 027, 028, 029, 031, ... , 048, 049, 050, 051, 052, 053, 054, 056, 057, 058, 060, 062, 063, 064, 065, 066, 069, 070, 071, 072\n",
      "Overlap (TRIALS ∩ REPEATS): 20\n",
      "  006, 009, 011, 016, 021, 029, 032, 036, 041, 042, 047, 048, 049, 054, 056, 057, 058, 062, 065, 071\n",
      "Only in TRIALS: 31\n",
      "  001, 003, 008, 013, 015, 017, 019, 020, 024, 025, 026, 027, 028, 031, 033, 034, 037, 038, 039, 040, 043, 050, 051, 052, 053, 060, 063, 064, 066, 069, 070\n",
      "Only in REPEATS: 1\n",
      "  072\n",
      "\n",
      "========================================================================\n",
      "Numeric Consistency Check\n",
      "========================================================================\n",
      "Max observed participant ID: 72\n",
      "Total unique participants across both: 52\n",
      "Count of missing IDs between 1 and 72: 20\n",
      "Missing IDs: 2, 4, 5, 7, 10, 12, 14, 18, 22, 23, 30, 35, 44, 45, 46, 55, 59, 61, 67, 68\n",
      "\n",
      "Tip: A high max ID (e.g., 072) with fewer unique participants (e.g., 52) indicates non-contiguous ID assignment (some IDs unused or absent in the released data).\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from typing import Set, Tuple, List\n",
    "\n",
    "# ---------------------------\n",
    "# CONFIG: set your folder paths\n",
    "# ---------------------------\n",
    "TRIALS_DIR = \"first trials\"\n",
    "REPEATS_DIR = \"repeats\"\n",
    "\n",
    "# ---------------------------\n",
    "# Helper functions\n",
    "# ---------------------------\n",
    "PID_TASK_PATTERN = re.compile(r\"^(\\d+)_([0-3])\\.csv$\", re.IGNORECASE)\n",
    "\n",
    "def extract_participant_ids(folder: str) -> Set[str]:\n",
    "    \"\"\"\n",
    "    Extract participant IDs from filenames in a folder.\n",
    "    Filenames expected as '<participantid>_<taskid>.csv', e.g. '029_2.csv'.\n",
    "    Returns a set of participant IDs as zero-padded strings (as seen in filenames).\n",
    "    \"\"\"\n",
    "    pids = set()\n",
    "    if not os.path.isdir(folder):\n",
    "        print(f\"[WARN] Folder not found: {folder}\")\n",
    "        return pids\n",
    "\n",
    "    for fname in os.listdir(folder):\n",
    "        if not fname.lower().endswith(\".csv\"):\n",
    "            continue\n",
    "        m = PID_TASK_PATTERN.match(fname)\n",
    "        if m:\n",
    "            pid = m.group(1)  # keep as string to preserve leading zeros\n",
    "            pids.add(pid)\n",
    "        else:\n",
    "            # If pattern doesn't match, try a more lenient parse\n",
    "            # (handles filenames like '029_2_extra.csv' if ever present)\n",
    "            base = os.path.splitext(fname)[0]\n",
    "            parts = base.split(\"_\")\n",
    "            if len(parts) >= 2 and parts[0].isdigit():\n",
    "                pids.add(parts[0])\n",
    "            else:\n",
    "                print(f\"[WARN] Skipped (unexpected name): {fname}\")\n",
    "    return pids\n",
    "\n",
    "def to_int_set(pids: Set[str]) -> Set[int]:\n",
    "    \"\"\"Convert string IDs (possibly zero-padded) to integers safely.\"\"\"\n",
    "    out = set()\n",
    "    for pid in pids:\n",
    "        try:\n",
    "            out.add(int(pid))\n",
    "        except ValueError:\n",
    "            pass\n",
    "    return out\n",
    "\n",
    "def pretty_ids(pids: Set[str]) -> List[str]:\n",
    "    \"\"\"Return a sorted list of IDs (as strings) with natural numeric ordering.\"\"\"\n",
    "    return sorted(pids, key=lambda s: (len(s), int(s)))\n",
    "\n",
    "def missing_ids(all_pid_ints: Set[int]) -> Tuple[int, List[int]]:\n",
    "    \"\"\"Return (max_id, sorted_missing_ids) based on observed integer IDs.\"\"\"\n",
    "    if not all_pid_ints:\n",
    "        return 0, []\n",
    "    max_id = max(all_pid_ints)\n",
    "    expected = set(range(1, max_id + 1))\n",
    "    missing = sorted(expected - all_pid_ints)\n",
    "    return max_id, missing\n",
    "\n",
    "def print_header(title: str):\n",
    "    print(\"\\n\" + \"=\" * 72)\n",
    "    print(title)\n",
    "    print(\"=\" * 72)\n",
    "\n",
    "def print_list(title: str, items: List[str], max_show: int = 40):\n",
    "    print(f\"{title}: {len(items)}\")\n",
    "    if not items:\n",
    "        return\n",
    "    if len(items) <= max_show:\n",
    "        print(\"  \" + \", \".join(items))\n",
    "    else:\n",
    "        head = \", \".join(items[:max_show//2])\n",
    "        tail = \", \".join(items[-max_show//2:])\n",
    "        print(f\"  {head}, ... , {tail}\")\n",
    "\n",
    "# ---------------------------\n",
    "# Main analysis\n",
    "# ---------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # 1) Collect participant IDs from each folder\n",
    "    trials_pids_str  = extract_participant_ids(TRIALS_DIR)\n",
    "    repeats_pids_str = extract_participant_ids(REPEATS_DIR)\n",
    "\n",
    "    # 2) Convert to numeric sets for stats (while keeping string form for display)\n",
    "    trials_pids_int  = to_int_set(trials_pids_str)\n",
    "    repeats_pids_int = to_int_set(repeats_pids_str)\n",
    "\n",
    "    # 3) Unions & intersections\n",
    "    union_pids_str = trials_pids_str | repeats_pids_str\n",
    "    inter_pids_str = trials_pids_str & repeats_pids_str\n",
    "    only_trials_str  = trials_pids_str - repeats_pids_str\n",
    "    only_repeats_str = repeats_pids_str - trials_pids_str\n",
    "\n",
    "    # 4) Missing ID analysis (using integer IDs)\n",
    "    all_pid_ints = trials_pids_int | repeats_pids_int\n",
    "    max_id, missing = missing_ids(all_pid_ints)\n",
    "\n",
    "    # 5) Pretty sorted lists for display\n",
    "    trials_sorted   = pretty_ids(trials_pids_str)\n",
    "    repeats_sorted  = pretty_ids(repeats_pids_str)\n",
    "    union_sorted    = pretty_ids(union_pids_str)\n",
    "    inter_sorted    = pretty_ids(inter_pids_str)\n",
    "    only_trials_sorted  = pretty_ids(only_trials_str)\n",
    "    only_repeats_sorted = pretty_ids(only_repeats_str)\n",
    "\n",
    "    # ---------------------------\n",
    "    # PRINT REPORT\n",
    "    # ---------------------------\n",
    "    print_header(\"Participant ID Summary (by folder)\")\n",
    "    print_list(\"Unique participants in TRIALS\", trials_sorted)\n",
    "    print_list(\"Unique participants in REPEATS\", repeats_sorted)\n",
    "\n",
    "    print_header(\"Combined Participants\")\n",
    "    print_list(\"Union (TRIALS ∪ REPEATS)\", union_sorted)\n",
    "    print_list(\"Overlap (TRIALS ∩ REPEATS)\", inter_sorted)\n",
    "    print_list(\"Only in TRIALS\", only_trials_sorted)\n",
    "    print_list(\"Only in REPEATS\", only_repeats_sorted)\n",
    "\n",
    "    print_header(\"Numeric Consistency Check\")\n",
    "    print(f\"Max observed participant ID: {max_id if max_id else 'N/A'}\")\n",
    "    print(f\"Total unique participants across both: {len(union_pids_str)}\")\n",
    "    print(f\"Count of missing IDs between 1 and {max_id}: {len(missing)}\")\n",
    "    if missing:\n",
    "        # Show first and last few for readability\n",
    "        if len(missing) <= 40:\n",
    "            print(\"Missing IDs:\", \", \".join(map(str, missing)))\n",
    "        else:\n",
    "            head = \", \".join(map(str, missing[:20]))\n",
    "            tail = \", \".join(map(str, missing[-20:]))\n",
    "            print(f\"Missing IDs: {head}, ... , {tail}\")\n",
    "\n",
    "    print(\"\\nTip: A high max ID (e.g., 072) with fewer unique participants (e.g., 52) indicates non-contiguous ID assignment (some IDs unused or absent in the released data).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94138a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (1.24.4)\n",
      "Requirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (1.6.1)\n",
      "Requirement already satisfied: shap in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (0.48.0)\n",
      "Requirement already satisfied: matplotlib in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (3.5.3)\n",
      "Requirement already satisfied: seaborn in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (0.13.2)\n",
      "Requirement already satisfied: joblib in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (1.3.1)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (4.67.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from scikit-learn) (1.9.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: packaging>20.9 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from shap) (21.3)\n",
      "Requirement already satisfied: slicer==0.0.8 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from shap) (0.0.8)\n",
      "Requirement already satisfied: numba>=0.54 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from shap) (0.61.0)\n",
      "Requirement already satisfied: cloudpickle in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from shap) (3.1.1)\n",
      "Requirement already satisfied: typing-extensions in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from shap) (4.12.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib) (4.36.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from numba>=0.54->shap) (0.44.0)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas numpy scikit-learn shap matplotlib seaborn joblib tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a88cd14d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Could not infer label column. Please pass --label-col.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mshap_explain\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m run_shap_pipeline\n\u001b[1;32m      4\u001b[0m args \u001b[38;5;241m=\u001b[39m types\u001b[38;5;241m.\u001b[39mSimpleNamespace(\n\u001b[1;32m      5\u001b[0m     input_csv\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mphase2_complete_features.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      6\u001b[0m     label_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,            \u001b[38;5;66;03m# let it auto-derive from file_path or condition\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m     top_dependence\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m\n\u001b[1;32m     17\u001b[0m )\n\u001b[0;32m---> 19\u001b[0m \u001b[43mrun_shap_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Final Project/shap_explain.py:320\u001b[0m, in \u001b[0;36mrun_shap_pipeline\u001b[0;34m(args)\u001b[0m\n\u001b[1;32m    318\u001b[0m label_col \u001b[38;5;241m=\u001b[39m args\u001b[38;5;241m.\u001b[39mlabel_col \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mlabel_col \u001b[38;5;28;01melse\u001b[39;00m infer_label_col(df)\n\u001b[1;32m    319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m label_col \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not infer label column. Please pass --label-col.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    322\u001b[0m group_col \u001b[38;5;241m=\u001b[39m args\u001b[38;5;241m.\u001b[39mgroup_col \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mgroup_col \u001b[38;5;28;01melse\u001b[39;00m infer_group_col(df)\n\u001b[1;32m    323\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m group_col \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: Could not infer label column. Please pass --label-col."
     ]
    }
   ],
   "source": [
    "import types\n",
    "from shap_explain import run_shap_pipeline\n",
    "\n",
    "args = types.SimpleNamespace(\n",
    "    input_csv=\"phase2_complete_features.csv\",\n",
    "    label_col=None,            # let it auto-derive from file_path or condition\n",
    "    group_col=None,            # auto-detect participant_id if exists\n",
    "    drop_cols=None,\n",
    "    model=\"rf\",                # or \"svm\", \"lr\"\n",
    "    test_size=0.2,\n",
    "    seed=42,\n",
    "    output_dir=\"shap_rf_outputs\",\n",
    "    kernel_bg_samples=200,\n",
    "    kernel_test_samples=200,\n",
    "    kernel_nsamples=\"auto\",\n",
    "    top_dependence=8\n",
    ")\n",
    "\n",
    "run_shap_pipeline(args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2c08cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (25.1)\n",
      "Collecting pip\n",
      "  Downloading pip-25.2-py3-none-any.whl.metadata (4.7 kB)\n",
      "Downloading pip-25.2-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 25.1\n",
      "    Uninstalling pip-25.1:\n",
      "      Successfully uninstalled pip-25.1\n",
      "\u001b[33m  WARNING: The scripts pip, pip3 and pip3.10 are installed in '/Library/Frameworks/Python.framework/Versions/3.10/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
      "\u001b[0mSuccessfully installed pip-25.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (1.24.4)\n",
      "Requirement already satisfied: scikit-learn in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (1.6.1)\n",
      "Requirement already satisfied: shap in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (0.48.0)\n",
      "Requirement already satisfied: matplotlib in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (3.5.3)\n",
      "Requirement already satisfied: seaborn in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (0.13.2)\n",
      "Requirement already satisfied: tqdm in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (4.67.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from scikit-learn) (1.9.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from scikit-learn) (1.3.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: packaging>20.9 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from shap) (21.3)\n",
      "Requirement already satisfied: slicer==0.0.8 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from shap) (0.0.8)\n",
      "Requirement already satisfied: numba>=0.54 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from shap) (0.61.0)\n",
      "Requirement already satisfied: cloudpickle in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from shap) (3.1.1)\n",
      "Requirement already satisfied: typing-extensions in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from shap) (4.12.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib) (4.36.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: llvmlite<0.45,>=0.44.0dev0 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from numba>=0.54->shap) (0.44.0)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U pip\n",
    "%pip install pandas numpy scikit-learn shap matplotlib seaborn tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d3904a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-3.0.4-py3-none-macosx_10_15_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting lightgbm\n",
      "  Downloading lightgbm-4.6.0-py3-none-macosx_10_15_x86_64.whl.metadata (17 kB)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from xgboost) (1.24.4)\n",
      "Requirement already satisfied: scipy in /Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages (from xgboost) (1.9.0)\n",
      "Downloading xgboost-3.0.4-py3-none-macosx_10_15_x86_64.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading lightgbm-4.6.0-py3-none-macosx_10_15_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: xgboost, lightgbm\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [lightgbm]1/2\u001b[0m [lightgbm]\n",
      "\u001b[1A\u001b[2KSuccessfully installed lightgbm-4.6.0 xgboost-3.0.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost lightgbm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "50cf2b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(734, 17)\n",
      "['duration_samples', 'duration_time', 'mean_velocity', 'std_velocity', 'mean_acceleration', 'mean_jerk', 'blink_count', 'blink_rate', 'participant_id', 'trial_number', 'condition', 'trial_type', 'file_path', 'gaze_entropy', 'fixation_count', 'mean_fixation_duration_ms', 'mean_fixation_dispersion']\n",
      "                                                0                       1  \\\n",
      "duration_samples                             7450                    7450   \n",
      "duration_time                           46.543963               46.543963   \n",
      "mean_velocity                            2.118361                2.118361   \n",
      "std_velocity                             1.529666                1.529666   \n",
      "mean_acceleration                        0.000438                0.000438   \n",
      "mean_jerk                                0.000066                0.000066   \n",
      "blink_count                                     0                       0   \n",
      "blink_rate                                    0.0                     0.0   \n",
      "participant_id                                 29                      29   \n",
      "trial_number                                    2                       2   \n",
      "condition                                 Unknown                 Unknown   \n",
      "trial_type                                  first                   first   \n",
      "file_path                  first trials/029_2.csv  first trials/029_2.csv   \n",
      "gaze_entropy                             4.117958                4.117958   \n",
      "fixation_count                                  0                       0   \n",
      "mean_fixation_duration_ms                     NaN                     NaN   \n",
      "mean_fixation_dispersion                      NaN                     NaN   \n",
      "\n",
      "                                                2  \n",
      "duration_samples                             7450  \n",
      "duration_time                           46.543963  \n",
      "mean_velocity                            2.118361  \n",
      "std_velocity                             1.529666  \n",
      "mean_acceleration                        0.000438  \n",
      "mean_jerk                                0.000066  \n",
      "blink_count                                     0  \n",
      "blink_rate                                    0.0  \n",
      "participant_id                                 29  \n",
      "trial_number                                    2  \n",
      "condition                                 Unknown  \n",
      "trial_type                                  first  \n",
      "file_path                  first trials/029_2.csv  \n",
      "gaze_entropy                             4.229492  \n",
      "fixation_count                                  0  \n",
      "mean_fixation_duration_ms                     NaN  \n",
      "mean_fixation_dispersion                      NaN  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"phase2_complete_features.csv\")\n",
    "print(df.shape)\n",
    "print(df.columns.tolist())\n",
    "print(df.head(3).T)  # vertical view\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "58f4fff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: phase2_complete_features_with_label.csv\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     1.0000    1.0000    1.0000        99\n",
      "           1     1.0000    1.0000    1.0000       102\n",
      "\n",
      "    accuracy                         1.0000       201\n",
      "   macro avg     1.0000    1.0000    1.0000       201\n",
      "weighted avg     1.0000    1.0000    1.0000       201\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "This RandomForestClassifier estimator requires y to be passed, but the target y is None.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 27>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLabel column already present.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# 2) Run SHAP pipeline (RF, subject-wise split via participant_id)\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m \u001b[43mrun_shap_pipeline_fixed\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_csv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mphase2_complete_features_with_label.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlabel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparticipant_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m               \u001b[49m\u001b[38;5;66;43;03m# prevents identity leakage\u001b[39;49;00m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdrop_cols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfile_path\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrial_type\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcondition\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# drop meta columns\u001b[39;49;00m\n\u001b[1;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                               \u001b[49m\u001b[38;5;66;43;03m# use RF for SHAP TreeExplainer\u001b[39;49;00m\n\u001b[1;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshap_rf_outputs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     36\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Final Project/shap_explain_fixed.py:295\u001b[0m, in \u001b[0;36mrun_shap_pipeline_fixed\u001b[0;34m(input_csv, label_col, group_col, drop_cols, model, test_size, seed, output_dir)\u001b[0m\n\u001b[1;32m    292\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    294\u001b[0m \u001b[38;5;66;03m# Compute SHAP matrices after preprocessing and use DataFrame with feature names\u001b[39;00m\n\u001b[0;32m--> 295\u001b[0m shap_values, feat_names, X_test_trans \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_tree_shap_and_feature_names\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpipe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_cols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_cols\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;66;03m# Build DataFrame for X_test transformed with column names (critical for plotting)\u001b[39;00m\n\u001b[1;32m    300\u001b[0m X_test_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(X_test_trans, columns\u001b[38;5;241m=\u001b[39mfeat_names)\n",
      "File \u001b[0;32m~/Desktop/Final Project/shap_explain_fixed.py:140\u001b[0m, in \u001b[0;36mcompute_tree_shap_and_feature_names\u001b[0;34m(pipeline, X_train, X_test, feature_cols)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;124;03mFit the preprocessing on training set; transform both X_train and X_test to dense arrays.\u001b[39;00m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;124;03mCompute TreeExplainer SHAP on the underlying estimator.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;124;03m- X_test_transformed: np.ndarray used for plotting with shap\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;66;03m# Fit pipeline on training data:\u001b[39;00m\n\u001b[0;32m--> 140\u001b[0m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfeature_cols\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# y passed later to clf\u001b[39;00m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;66;03m# Extract fitted preprocessing steps for transformation:\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;66;03m# For RF: pipeline has ['imputer', 'clf']\u001b[39;00m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;66;03m# For SVM/LR: pipeline has ['imputer', 'scaler', 'clf']\u001b[39;00m\n\u001b[1;32m    145\u001b[0m steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(pipeline\u001b[38;5;241m.\u001b[39mnamed_steps)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/pipeline.py:662\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    656\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    657\u001b[0m         last_step_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_metadata_for_step(\n\u001b[1;32m    658\u001b[0m             step_idx\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    659\u001b[0m             step_params\u001b[38;5;241m=\u001b[39mrouted_params[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]],\n\u001b[1;32m    660\u001b[0m             all_params\u001b[38;5;241m=\u001b[39mparams,\n\u001b[1;32m    661\u001b[0m         )\n\u001b[0;32m--> 662\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_final_estimator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mlast_step_params\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfit\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    664\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/base.py:1389\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1382\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1385\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1386\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1387\u001b[0m     )\n\u001b[1;32m   1388\u001b[0m ):\n\u001b[0;32m-> 1389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:360\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(y):\n\u001b[1;32m    358\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse multilabel-indicator for y is not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 360\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    363\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    364\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmulti_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    365\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsc\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    366\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDTYPE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    367\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    368\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;66;03m# _compute_missing_values_in_feature_mask checks if X has missing values and\u001b[39;00m\n\u001b[1;32m    370\u001b[0m \u001b[38;5;66;03m# will raise an error if the underlying tree base estimator can't handle missing\u001b[39;00m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;66;03m# values. Only the criterion is required to determine if the tree supports\u001b[39;00m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;66;03m# missing values.\u001b[39;00m\n\u001b[1;32m    373\u001b[0m estimator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimator)(criterion\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/utils/validation.py:2922\u001b[0m, in \u001b[0;36mvalidate_data\u001b[0;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[1;32m   2920\u001b[0m tags \u001b[38;5;241m=\u001b[39m get_tags(_estimator)\n\u001b[1;32m   2921\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m tags\u001b[38;5;241m.\u001b[39mtarget_tags\u001b[38;5;241m.\u001b[39mrequired:\n\u001b[0;32m-> 2922\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2923\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_estimator\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m estimator \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2924\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires y to be passed, but the target y is None.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2925\u001b[0m     )\n\u001b[1;32m   2927\u001b[0m no_val_X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28misinstance\u001b[39m(X, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m X \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2928\u001b[0m no_val_y \u001b[38;5;241m=\u001b[39m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(y, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m y \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: This RandomForestClassifier estimator requires y to be passed, but the target y is None."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from shap_explain_fixed import run_shap_pipeline_fixed\n",
    "\n",
    "# 1) If needed: create label from file_path (_0/_1 -> 0, _2/_3 -> 1)\n",
    "df = pd.read_csv(\"phase2_complete_features.csv\")\n",
    "\n",
    "def derive_label_from_path(path):\n",
    "    import re, os\n",
    "    basename = os.path.basename(str(path)).strip()\n",
    "    m = re.search(r'_(\\d)\\.csv$', basename)\n",
    "    if m:\n",
    "        tid = int(m.group(1))\n",
    "        return 1 if tid in (2,3) else 0\n",
    "    return None\n",
    "\n",
    "if 'label' not in df.columns:\n",
    "    df['label'] = df['file_path'].apply(derive_label_from_path)\n",
    "    df = df.dropna(subset=['label'])\n",
    "    df['label'] = df['label'].astype(int)\n",
    "    df.to_csv(\"phase2_complete_features_with_label.csv\", index=False)\n",
    "    print(\"Saved: phase2_complete_features_with_label.csv\")\n",
    "else:\n",
    "    print(\"Label column already present.\")\n",
    "\n",
    "# 2) Run SHAP pipeline (RF, subject-wise split via participant_id)\n",
    "run_shap_pipeline_fixed(\n",
    "    input_csv=\"phase2_complete_features_with_label.csv\",\n",
    "    label_col=\"label\",\n",
    "    group_col=\"participant_id\",               # prevents identity leakage\n",
    "    drop_cols=[\"file_path\", \"trial_type\", \"condition\"],  # drop meta columns\n",
    "    model=\"rf\",                               # use RF for SHAP TreeExplainer\n",
    "    test_size=0.2,\n",
    "    seed=42,\n",
    "    output_dir=\"shap_rf_outputs\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "568c1322",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_saliency_overlay(time_s, saliency, velocity, blink_flag, out_path):\n",
    "    import matplotlib.pyplot as plt\n",
    "    fig, ax1 = plt.subplots(figsize=(11,3.5))\n",
    "\n",
    "    ax1.plot(time_s, saliency, color='crimson', lw=2, label='Grad-CAM++')\n",
    "    ax1.set_ylabel('Saliency', color='crimson')\n",
    "    ax1.set_xlabel('Time (sec)')\n",
    "    ax1.tick_params(axis='y', labelcolor='crimson')\n",
    "\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(time_s, velocity, color='navy', alpha=0.6, label='Velocity')\n",
    "    ax2.fill_between(time_s, 0, blink_flag, color='gold', alpha=0.3, label='Blink')\n",
    "    ax2.set_ylabel('Velocity / Blink')\n",
    "\n",
    "    lines1, labels1 = ax1.get_legend_handles_labels()\n",
    "    lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "    ax1.legend(lines1+lines2, labels1+labels2, loc='upper right')\n",
    "\n",
    "    plt.title(\"Temporal saliency aligned with dynamic signals\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_path, dpi=300)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e7e228e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_classwise_mean_saliency(saliency_class0, saliency_class1, out_path):\n",
    "    import matplotlib.pyplot as plt\n",
    "    T = len(saliency_class0)\n",
    "    t = np.arange(T) / 60.0  # seconds\n",
    "    plt.figure(figsize=(10,3))\n",
    "    plt.plot(t, saliency_class0, label='Low Load', color='teal', lw=2)\n",
    "    plt.plot(t, saliency_class1, label='High Load', color='crimson', lw=2)\n",
    "    plt.xlabel(\"Time (sec)\")\n",
    "    plt.ylabel(\"Mean saliency\")\n",
    "    plt.title(\"Per-class average temporal saliency (Grad-CAM++)\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(out_path, dpi=300)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b27f0b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated fig_feature_pipeline_proper_large.pdf, fig_feature_pipeline_proper_large.svg, and fig_feature_pipeline_proper_large.png (at 600 DPI)\n"
     ]
    }
   ],
   "source": [
    "from graphviz import Digraph\n",
    "\n",
    "def esc(text: str) -> str:\n",
    "    \"\"\"Escape special characters for Graphviz HTML-like labels.\"\"\"\n",
    "    return (text\n",
    "            .replace('&', '&amp;')\n",
    "            .replace('<', '&lt;')\n",
    "            .replace('>', '&gt;'))\n",
    "\n",
    "def _box(label_title: str, label_sub: str) -> str:\n",
    "    \"\"\"\n",
    "    Build an HTML-like label with bold title and smaller subtitle on the next line.\n",
    "    Graphviz renders this crisply in PDF/SVG.\n",
    "    \"\"\"\n",
    "    return f'''<\n",
    "      <B>{esc(label_title)}</B><BR ALIGN=\"CENTER\"/>\n",
    "      <FONT POINT-SIZE=\"14\">{esc(label_sub)}</FONT>\n",
    "    >'''\n",
    "\n",
    "\n",
    "def build_pipeline_report(\n",
    "    filename=\"fig_feature_pipeline_proper_large\",\n",
    "    pdf_size=\"10,6!\",      # target size in inches (width,height) for PDF/SVG\n",
    "    png_dpi=\"600\"          # DPI for raster export\n",
    "):\n",
    "    # Use DOT engine and start with vector (PDF/SVG)\n",
    "    g = Digraph(engine=\"dot\", filename=filename, format=\"pdf\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # Global graph attributes\n",
    "    # -----------------------------\n",
    "    g.attr(\n",
    "        \"graph\",\n",
    "        rankdir=\"TB\",           # overall top-to-bottom direction (tiled into two rows)\n",
    "        bgcolor=\"white\",\n",
    "        margin=\"0.2\",\n",
    "        pad=\"0.2\",\n",
    "        nodesep=\"0.65\",         # spacing between nodes in same rank\n",
    "        ranksep=\"0.8\",          # spacing between ranks (rows)\n",
    "        splines=\"ortho\",        # orthogonal edges\n",
    "        concentrate=\"true\",     # merge parallel edges where possible\n",
    "        outputorder=\"edgesfirst\",\n",
    "        size=pdf_size,          # constrain overall figure size (for PDF/SVG)\n",
    "        ratio=\"compress\"        # compress whitespace\n",
    "    )\n",
    "\n",
    "    g.attr(\n",
    "        \"node\",\n",
    "        shape=\"box\",\n",
    "        style=\"rounded,filled\",\n",
    "        color=\"#444444\",\n",
    "        fillcolor=\"#F7F9FC\",    # subtle fill\n",
    "        fontname=\"Helvetica\",\n",
    "        fontsize=\"18\",          # good for print while not overwhelming\n",
    "        margin=\"0.20,0.12\",     # inner padding within node\n",
    "        penwidth=\"1.6\"\n",
    "    )\n",
    "\n",
    "    g.attr(\n",
    "        \"edge\",\n",
    "        color=\"#555555\",\n",
    "        penwidth=\"1.6\",\n",
    "        arrowsize=\"0.9\"\n",
    "    )\n",
    "\n",
    "    # -----------------------------\n",
    "    # Nodes (two-row layout)\n",
    "    # -----------------------------\n",
    "    # Top row\n",
    "    g.node(\"raw\",     label=_box(\"Raw Eye-Tracking Data\", \"Fixations · Saccades · Blinks\"))\n",
    "    g.node(\"preproc\", label=_box(\"Preprocessing\", \"Interpolation · Smoothing · Blink Handling\"))\n",
    "    g.node(\"segment\", label=_box(\"Temporal Segmentation\", \"2s Windows (Non-Overlapping)\"))\n",
    "    g.node(\"features\",label=_box(\"Feature Extraction\", \"Velocity · Entropy · Blink Rate\"))\n",
    "\n",
    "    # Bottom row\n",
    "    g.node(\"fusion\",  label=_box(\"Feature Fusion &amp; Cleaning\", \"Merge · Normalize · Deduplicate\"))\n",
    "    g.node(\"csvs\",    label=_box(\"Structured CSV Exports\", \"Trial-Level &amp; Epoch-Level\"))\n",
    "    g.node(\"models\",  label=_box(\"Downstream Models\", \"Classical ML · Deep Learning\"))\n",
    "\n",
    "    # -----------------------------\n",
    "    # Rank constraints (tile into two rows)\n",
    "    # -----------------------------\n",
    "    with g.subgraph() as top:\n",
    "        top.attr(rank=\"same\")\n",
    "        top.node(\"raw\")\n",
    "        top.node(\"preproc\")\n",
    "        top.node(\"segment\")\n",
    "        top.node(\"features\")\n",
    "\n",
    "    with g.subgraph() as bottom:\n",
    "        bottom.attr(rank=\"same\")\n",
    "        bottom.node(\"fusion\")\n",
    "        bottom.node(\"csvs\")\n",
    "        bottom.node(\"models\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # Primary flow edges\n",
    "    # -----------------------------\n",
    "    # Top row connections\n",
    "    g.edge(\"raw\", \"preproc\")\n",
    "    g.edge(\"preproc\", \"segment\")\n",
    "    g.edge(\"segment\", \"features\")\n",
    "\n",
    "    # Vertical flow from top to bottom row\n",
    "    g.edge(\"features\", \"fusion\")\n",
    "\n",
    "    # Bottom row connections\n",
    "    g.edge(\"fusion\", \"csvs\")\n",
    "    g.edge(\"csvs\", \"models\")\n",
    "\n",
    "    # Invisible edges to keep columns aligned top/bottom\n",
    "    g.edge(\"preproc\", \"csvs\", style=\"invis\")\n",
    "    g.edge(\"segment\", \"fusion\", style=\"invis\")\n",
    "\n",
    "    # -----------------------------\n",
    "    # Render vector formats first (PDF + SVG)\n",
    "    # -----------------------------\n",
    "    g.render(cleanup=True)   # PDF\n",
    "    g.format = \"svg\"\n",
    "    g.render(cleanup=True)   # SVG (great for web and vector editing)\n",
    "\n",
    "    # -----------------------------\n",
    "    # Render high-DPI PNG for screens/slides\n",
    "    # -----------------------------\n",
    "    g.format = \"png\"\n",
    "    # IMPORTANT: set PNG DPI right before rendering raster output\n",
    "    g.attr(\"graph\", dpi=str(png_dpi))\n",
    "    g.render(cleanup=True)\n",
    "\n",
    "    return f\"Generated {filename}.pdf, {filename}.svg, and {filename}.png (at {png_dpi} DPI)\"\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(build_pipeline_report())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
